{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Training for evaluating a new network\n",
    "\n",
    "This will test the new network on two tasks\n",
    "\n",
    "1. Single object performance (caterpillar, baymax, starbot dataset) with no cross-object loss\n",
    "2. Class consistent performance on shoes dataset\n",
    "\n",
    "Set the `name` variable below to a distinctive name for this network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dense_correspondence_manipulation.utils.utils as utils\n",
    "utils.add_dense_correspondence_to_python_path()\n",
    "from dense_correspondence.training.training import *\n",
    "import sys\n",
    "import logging\n",
    "import copy\n",
    "# utils.set_default_cuda_visible_devices()\n",
    "utils.set_cuda_visible_devices([0]) # use this to manually set CUDA_VISIBLE_DEVICES\n",
    "\n",
    "from dense_correspondence.training.training import DenseCorrespondenceTraining\n",
    "from dense_correspondence.dataset.spartan_dataset_masked import SpartanDataset\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config_file = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence', \n",
    "                               'training', 'training.yaml')\n",
    "\n",
    "default_train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "\n",
    "##### CHANGE THIS TO YOUR NETWORK NAME ##############\n",
    "name = \"standard\"\n",
    "\n",
    "logging_dir = os.path.join(\"trained_models/benchmark\", name) # this is where trained models will be saved\n",
    "num_iterations = 3500\n",
    "num_image_pairs = 100\n",
    "\n",
    "\n",
    "default_train_config['training']['num_iterations'] = num_iterations\n",
    "default_train_config['training']['logging_dir'] = logging_dir\n",
    "\n",
    "\n",
    "\n",
    "TRAIN = True\n",
    "EVALUATE = True\n",
    "EVALUATE_KEYPOINTS = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Eval on Caterpillar-Baymax-Starbot dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config_filename = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence', \n",
    "                               'dataset', 'composite', 'caterpillar_baymax_starbot_all_front_single_only.yaml')\n",
    "dataset_config = utils.getDictFromYamlFilename(dataset_config_filename)\n",
    "dataset = SpartanDataset(config=dataset_config)\n",
    "\n",
    "# make any necessary tweaks to your default_train_config\n",
    "train_config = copy.copy(default_train_config)\n",
    "\n",
    "\n",
    "train = DenseCorrespondenceTraining(dataset=dataset, config=train_config)\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "network_name = \"cbs_%d\" %(train_config['dense_correspondence_network']['descriptor_dimension'])\n",
    "train._config[\"training\"][\"logging_dir\"] = logging_dir\n",
    "train._config[\"training\"][\"logging_dir_name\"] = network_name\n",
    "\n",
    "\n",
    "if TRAIN:\n",
    "    train.run()\n",
    "\n",
    "model_folder = os.path.join(logging_dir, name)\n",
    "model_folder = utils.convert_data_relative_path_to_absolute_path(model_folder)\n",
    "\n",
    "if EVALUATE:\n",
    "    DCE = DenseCorrespondenceEvaluation\n",
    "    DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Eval class consistent network on shoes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config_filename = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence', \n",
    "                               'dataset', 'composite', 'shoe_train_all_shoes.yaml')\n",
    "dataset_config = utils.getDictFromYamlFilename(dataset_config_filename)\n",
    "dataset = SpartanDataset(config=dataset_config)\n",
    "\n",
    "keypoint_data_file = \"evaluation_labeled_data/keypoints/shoe_keypoints.yaml\"\n",
    "\n",
    "# make any necessary tweaks to your default_train_config\n",
    "train_config = copy.copy(default_train_config)\n",
    "\n",
    "\n",
    "train = DenseCorrespondenceTraining(dataset=dataset, config=train_config)\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "network_name = \"shoes_consistent_%d\" %(train_config['dense_correspondence_network']['descriptor_dimension'])\n",
    "train._config[\"training\"][\"logging_dir\"] = logging_dir\n",
    "train._config[\"training\"][\"logging_dir_name\"] = network_name\n",
    "\n",
    "\n",
    "if TRAIN:\n",
    "    train.run()\n",
    "\n",
    "model_folder = os.path.join(logging_dir, name)\n",
    "model_folder = utils.convert_data_relative_path_to_absolute_path(model_folder)\n",
    "\n",
    "if EVALUATE:\n",
    "    DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs)\n",
    "\n",
    "if EVALUATE_KEYPOINTS:\n",
    "    DCE.run_cross_instance_keypoint_evaluation_on_network(model_folder, keypoint_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
